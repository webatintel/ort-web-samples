<html>

<head>
  <title>Stable Diffusion Turbo</title>
  <style>
    .onerow {
      display: flex;
    }
  </style>
  <link rel="stylesheet" href="sortable.min.css" />
  <link rel="stylesheet" href="profilingDisplayer.css" />

  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous" />
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm"
    crossorigin="anonymous"> </script>
</head>

<script src="sortable.min.js"></script>
<script src="profilingDisplayer.js"></script>

<script src="util.js"></script>
<script src="webgpuSteps.js"></script>
<script type="module">
  "use scrict";

  await loadOrt();
  // Transformer in /workspace/project/transformers.js/dist/transformers.js
  import { AutoTokenizer, env } from '../../transformers.js/dist/transformers.js';

  function logToConsoleAndPage(i) { console.log(i); document.getElementById('status').innerText += `\n${i}`; }
  function clearStatusLog(i) { document.getElementById('status').innerText = ''; }

  function getConfig() {
    const query = window.location.search.substring(1);
    var config = {
      // model: "models/onnx-sd-turbo-fp16",
      // model: "https://huggingface.co/schmuell/sd-turbo-ort-web/resolve/main",
      ortUrl: "default",
      modelUrl: "wp-27",
      provider: "webgpu",
      device: "gpu",
      // ort.env.wasm.numThreads
      threads: 1,
      // Tokenizer
      allowRemoteTokenizer: 0,
      allowLocalTokenizer: 1,

      // #Images to generate in a generation
      images: 1,

      // Auto test configures
      // autoTest: 0 for manual operation, 1 for auto testing
      autoTest: 0,
      prompt: "A cat and a dog swimming in a lake",
      generationRounds: 1,
      // profiler: 0 for not profiling, 1 for WebGPU profiling
      profiler: 0,
      // Start WebGPU profiling at WebGPUProfileBeginRound, if WebGPU profiling is enabled
      WebGPUProfileBeginRound: 0,
      // Stop WebGPU profiling at WebGPUProfileEndRound, 0 for never stop
      WebGPUProfileEndRound: 0,
      // Decide which ONNX models to be profiled, could be "all" or
      // comma-seperated list of {unet, text_encoder, vae_decoder}
      // E.g. "all" == "text_encoder,unet,vae_decoder"
      profilingModels: "all",
      // If waitForEachSessionRun, await WebGPU device complete all work after each ORT session run.
      waitForEachSessionRun: 0,


      // Pixel size is fixed for ort model
      // pixelHeight: 512,
      // pixelWidth: 512,
    };

    let vars = query.split("&");
    for (var i = 0; i < vars.length; i++) {
      let pair = vars[i].split("=");
      const key = pair[0];
      const value = decodeURIComponent(pair[1]);
      if (key in config) {
        if (typeof config[key] == "number") {
          config[key] = parseInt(value);
        }
        else {
          config[key] = value;
        }
      } else if (key.length > 0) {
        // throw new Error("unknown argument: " + pair[0]);
        logToConsoleAndPage(`unknown argument: ${key}${value ? `=${value}` : ''}`);
      }
    }

    if (config.profilingModels === "all") {
      config.profilingModels = "text_encoder,unet,vae_decoder";
    }
    config.profilingModels = config.profilingModels.split(',');

    return config;
  }

  const config = getConfig();

  // Tokenizer
  env.localModelPath = 'models';
  env.allowRemoteModels = config.allowRemoteTokenizer === 1;
  env.allowLocalModels = config.allowLocalTokenizer === 1;

  const models = {
    "unet": {
      name: "unet",
      hfTreeFullName: "onnxruntime/models",
      wp27TreeFullName: ".",
      modelFile: "sdturbo-unet.onnx",
      // size: 640,
      // should have 'steps: 1' but will fail to create the session
      opt: { freeDimensionOverrides: { batch_size: 1, num_channels: 4, height: 64, width: 64, sequence_length: 77, } },
    },
    "text_encoder": {
      name: "text_encoder",
      hfTreeFullName: "onnxruntime/models",
      wp27TreeFullName: ".",
      modelFile: "sdturbo-text-encoder.onnx",
      // size: 1700,
      // should have 'sequence_length: 77' but produces a bad image
      opt: { freeDimensionOverrides: { batch_size: 1, } },
    },
    "vae_decoder": {
      name: "vae_decoder",
      hfTreeFullName: "onnxruntime/models",
      wp27TreeFullName: ".",
      modelFile: "sdturbo-vae-decoder.onnx",
      //  size: 95,
      opt: { freeDimensionOverrides: { batch_size: 1, num_channels_latent: 4, height_latent: 64, width_latent: 64 } },
    }
  }

  // let loading;

  if (config.provider == "webgpu") {
    ort.env.wasm.numThreads = 1;
    ort.env.wasm.simd = true;
  } else {
    ort.env.wasm.numThreads = config.threads;
    ort.env.wasm.simd = true;
  }

  const opt = {
    executionProviders: [config.provider],
    enableMemPattern: false,
    enableCpuMemArena: false,
    extra: {
      session: {
        disable_prepacking: "1",
        use_device_allocator_for_initializers: "1",
        use_ort_model_bytes_directly: "1",
        use_ort_model_bytes_for_initializers: "1"
      }
    },
  };

  switch (config.provider) {
    case "webgpu":
      if (!("gpu" in navigator)) {
        throw new Error("webgpu is NOT supported");
      }
      opt.preferredOutputLocation = { last_hidden_state: "gpu-buffer" };
      break;
    case "webnn":
      if (!("ml" in navigator)) {
        throw new Error("webnn is NOT supported");
      }
      opt.executionProviders = [{
        name: "webnn",
        deviceType: config.device,
        powerPreference: 'default'
      }];
      break;
  }

  /*
  function init_latents(t) {
    const d = t.data;
    for (let i = 0; i < d.length; i++) {
      d[i] = d[i] * sigma;
    }
    return t;
  }

  function scale_model_inputs(t) {
    const d_i = t.data;
    const d_o = new Float32Array(d_i.length);

    const divi = (sigma ** 2 + 1) ** 0.5;
    for (let i = 0; i < d_i.length; i++) {
      d_o[i] = d_i[i] / divi;
    }
    return new ort.Tensor(d_o, t.dims);
  }

  function step(model_output, sample) {
    // poor mens EulerA.
    // Since this is just a example for sd-turbo, only implement the absolute minimum
    // needed to create an image
    const d_o = new Float32Array(model_output.data.length);
    const prev_sample = new ort.Tensor(d_o, model_output.dims);
    const sigma_hat = sigma * (gamma + 1);

    for (let i = 0; i < model_output.data.length; i++) {
      pred_original_sample = sample.data[i] - sigma_hat * model_output.data[i];
      derivative = (sample.data[i] - pred_original_sample) / sigma_hat;
      dt = 0 - sigma_hat;
      d_o[i] = (sample.data[i] + derivative * dt) / vae_scaling_factor;
    }
    return prev_sample;
  }

    function draw_image(t, image_nr) {
      let pix = t.data;
      for (var i = 0; i < pix.length; i++) {
        let x = pix[i];
        x = x / 2 + 0.5
        if (x < 0.) x = 0.;
        if (x > 1.) x = 1.;
        pix[i] = x;
      }
      const imageData = t.toImageData({ tensorLayout: 'NCWH', format: 'RGB' });
      const canvas = document.getElementById(`img_canvas_${image_nr}`);
      canvas.width = imageData.width;
      canvas.height = imageData.height;
      canvas.getContext('2d').putImageData(imageData, 0, 0);
      const div = document.getElementById(`img_div_${image_nr}`);
      div.style.opacity = 1.
    }
  */

  class SDTurbo {
    tokenizer = undefined;
    webgpuSteps;
    latent_shape;
    options;
    generatedRounds = 0;
    latestRoundProfiled = false;

    constructor(latent_shape = [1, 4, 64, 64], options = { pixelHeight: 512, pixelWidth: 512 }) {
      this.latent_shape = latent_shape;
      this.options = options;
    }

    async loadModelsAndInit(models, onDone = () => { }) {
      document.getElementById('model-progress').innerHTML = 'Downloading model files.';
      for (const [name, model] of Object.entries(models)) {
        model.model_file_url = `${getModelBaseUrl(config, model)}/${model.modelFile}`;
        // const model_bytes = await getModelOPFS(model.url.split('/').pop(), model.url, false);
        model.model_bytes = await fetchAndCache(model.model_file_url, logToConsoleAndPage);
      }
      document.getElementById('model-progress').innerHTML = 'Creating ORT sessions for models.';
      for (const [name, model] of Object.entries(models)) {
        logToConsoleAndPage(`Creating ORT session for model ${name}.`);
        const sess_opt = { ...opt, ...model.opt };
        // profiling
        //ort.env.webgpu.profiling = { mode: "default" };
        model.sess = await ort.InferenceSession.create(model.model_bytes, sess_opt);
        delete (model.model_bytes);
      }

      document.getElementById('model-progress').innerHTML = 'Seting up WebGPU steps.';
      logToConsoleAndPage(`Initializing SDTurboWebGPUSteps.`);

      const device = ort.env.webgpu.device;
      const canvas = document.getElementById(`canvas`);
      this.webgpuSteps = new SDTurboWebGPUSteps(this.latent_shape, this.options);
      this.webgpuSteps.webgpuResourceInitialize(device, canvas, ort);
      this.webgpuSteps.setupRandomLatent();

      clearStatusLog();
      document.getElementById('model-progress').innerHTML = 'Initialized finished. You may now click "Send" button to generate a new image.';

      setTimeout(onDone, 0);
    }

    async run(prompt) {
      try {
        const { textEncoderOutputsTensor, unetOutSampleTensor, unetSampleInputsTensor, decodedOutputsTensor } = this.webgpuSteps.getManagedTensors();

        if (this.tokenizer === undefined) {
          // this.tokenizer = await AutoTokenizer.from_pretrained('tokenizer', quantized = false, local_files_only = false);
          this.tokenizer = await AutoTokenizer.from_pretrained('tokenizer');
          this.tokenizer.pad_token_id = 0;
        }
        let canvases = [];
        // await loading;

        // const text = document.getElementById("user-input");
        // const prompt = text.value;
        const { input_ids } = await this.tokenizer(prompt, { padding: true, max_length: 77, truncation: true, return_tensor: false });

        if (config.profiler === 1) {
          if ((config.WebGPUProfileBeginRound <= this.generatedRounds) && ((config.WebGPUProfileEndRound === 0) || (this.generatedRounds < config.WebGPUProfileEndRound))) {
            // enableWebGPUProfiling(ort);
            this.latestRoundProfiled = true;
            logToConsoleAndPage('This round is WebGPU profiled.');
          } else {
            // disableWebGPUProfiling(ort);
            this.latestRoundProfiled = false;
          }
        } else {
          // disableWebGPUProfiling(ort);
          this.latestRoundProfiled = false;
        }
        // runWithProfiling run task, with WebGPU profiling enabled if latestRoundProfiled===True and useProfiling===True
        const runWithProfiling = async (useProfiling, task) => {
          if (this.latestRoundProfiled && useProfiling) {
            enableWebGPUProfiling(ort);
          }
          await task();
          if (config.waitForEachSessionRun) {
            await ort.env.webgpu.device.queue.onSubmittedWorkDone();
          }
          disableWebGPUProfiling(ort);
        };

        // text-encoder
        let start = performance.now();
        const executionStart = performance.now();
        const textEncoderOutputs = { last_hidden_state: textEncoderOutputsTensor };
        await runWithProfiling(
          config.profilingModels.includes('text_encoder'),
          async () => {
            await models.text_encoder.sess.run({ "input_ids": new ort.Tensor("int32", input_ids, [1, input_ids.length]) }, textEncoderOutputs);
          });

        let perf_info = [`text_encoder: ${(performance.now() - start).toFixed(1)}ms`];

        for (let j = 0; j < config.images; j++) {
          start = performance.now();
          let feed = {
            "sample": unetSampleInputsTensor,
            "timestep": new ort.Tensor("int64", [999n], [1]),
            "encoder_hidden_states": textEncoderOutputsTensor,
          };
          const unetOutSampleOutputs = { out_sample: unetOutSampleTensor };
          // const { out_sample } = await models.unet.sess.run(feed, unetOutSampleOutputs);
          // await models.unet.sess.run(feed, unetOutSampleOutputs);
          await runWithProfiling(
            config.profilingModels.includes('unet'),
            async () => {
              await models.unet.sess.run(feed, unetOutSampleOutputs);
            });
          perf_info.push(`unet: ${(performance.now() - start).toFixed(1)}ms`);

          this.webgpuSteps.stepLatentSpace();

          start = performance.now();
          const vaeDecodeInputs = { latent_sample: unetOutSampleTensor };
          const decodedOutputs = { sample: decodedOutputsTensor };
          // await models.vae_decoder.sess.run(vaeDecodeInputs, decodedOutputs);
          await runWithProfiling(
            config.profilingModels.includes('vae_decoder'),
            async () => {
              await models.vae_decoder.sess.run(vaeDecodeInputs, decodedOutputs);
            });
          // profiling
          // ort.env.webgpu.profiling = { mode: "" };

          await this.webgpuSteps.stepDraw();

          const executionEnd = performance.now();
          perf_info.push(`vae_decoder: ${(executionEnd - start).toFixed(1)}ms`);
          perf_info.push(`execution time: ${(executionEnd - executionStart).toFixed(1)}ms`);
          logToConsoleAndPage(perf_info.join(", "))
          perf_info = [];
        }

        //last_hidden_state.dispose();
        document.getElementById('model-progress').innerHTML = prompt;
        logToConsoleAndPage("done");
        this.generatedRounds++;

        this.webgpuSteps.setupRandomLatent();
      } catch (e) {
        logToConsoleAndPage(e);
      }
    }

  };

  let sd;
  let webgpuProfilingData;

  async function updateProfilingResultsPanel() {
    clearProfilingResultsPanel();
    // Handle the profiling log and generate the data tables
    const aggregatedTable = generateAggregatedProfilingTable(["Kernel", "Time (ms)", "Percentage (%)"], webgpuProfilingData);
    const dataTable = generateDataTable(["Index", "Kernel", "Time (ms)", "Shape"], webgpuProfilingData);
    // Display the data tables in the panel
    addDataTable(aggregatedTable, 'Aggregated time');
    addDataTable(dataTable, 'Detailed time');
    logToConsoleAndPage(`Profiling results updated.`);
  }

  async function doGeneration(doneCallback = () => { }) {
    const text = document.getElementById("user-input");
    const prompt = text.value;
    logToConsoleAndPage(`Generating with prompt: ${prompt}`);
    document.getElementById('model-progress').innerHTML = `Generating with prompt: ${prompt}`;
    setTimeout(async () => {
      await sd.run(prompt);
      if ((config.autoTest === 0) && (sd.latestRoundProfiled)) {
        logToConsoleAndPage(`Latest round profiled, updating result tables.`);
        setTimeout(async () => {
          await updateProfilingResultsPanel();
          doneCallback();
        }, 10);
      } else {
        setTimeout(doneCallback, 0);
      }
    }, 10);
  };

  async function sdInitDoneCallback() {
    if (config.profiler === 1) {
      enableProfilingResultsPanel();
      // Set up callback
      ({ webgpuProfilingData } = hookConsoleLogForProfilingDisplay(console));
    }
    if (config.autoTest === 1) {
      const autoGenerationStep = async (step) => {
        if (step >= config.generationRounds) {
          logToConsoleAndPage(`Autotest generating result tables.`);
          setTimeout(updateProfilingResultsPanel, 10);
        } else {
          logToConsoleAndPage(`Autotest generating round ${step}.`);
          doGeneration(() => { setTimeout(autoGenerationStep, 10, step + 1); });
        }
      }
      autoGenerationStep(0);
    }
  }

  async function init() {
    const text = document.getElementById("user-input");
    // text.value = "A cinematic shot of a baby racoon wearing an intricate italian priest robe.";
    // text.value = "Paris with the river in the background";
    // text.value = "A cat and a dog swimming in a lake";
    text.value = config.prompt;

    // Event listener for Ctrl + Enter or CMD + Enter
    document.getElementById('user-input').addEventListener('keydown', async function (e) {
      if ((e.ctrlKey || e.metaKey) && e.key === 'Enter') {
        doGeneration();
      }
    });
    document.getElementById('send-button').addEventListener('click', async function (e) {
      doGeneration();
    });

    // const latent_shape = [1, 4, 64, 64];
    // Fixed pixel size
    config.pixelHeight = 512;
    config.pixelWidth = 512;
    const latent_shape = [1, 4, config.pixelHeight / 8, config.pixelWidth / 8];
    sd = new SDTurbo(latent_shape, { pixelHeight: config.pixelHeight, pixelWidth: config.pixelWidth });
    await sd.loadModelsAndInit(models, sdInitDoneCallback);
  }

  window.onload = async () => {
    init();
  }
</script>

<body data-bs-theme="dark">

  <div class="profilingResultsPanelWrapper"
    style="width:80%; margin-left: auto; margin-right: auto; background-color: blanchedalmond;">
    <div id="profilingResultsPanel"></div>
  </div>

  <div class="container">
    <div class="row pt-3">
      <div class="col-md-9 col-12">
        <h2>Stable Diffusion Turbo</h2>
      </div>
    </div>
    <div class="container p-2 card" id="input-area">
      <div class="input-group">
        <textarea class="form-control" id="user-input" placeholder="Type your question here..."></textarea>
        <button id="send-button" class="btn btn-primary">Send</button>
      </div>
    </div>
    <!--<div id="image_area">
            <div class="onerow">
                <div id="img_div_0" style="margin-right: 4px;">
                    <canvas id="img_canvas_0"></canvas>
                </div>
                <div id="img_div_1" style="margin-right: 4px;">
                    <canvas id="img_canvas_1"></canvas>
                </div>
                <div id="img_div_2" style="margin-right: 4px;">
                    <canvas id="img_canvas_2"></canvas>
                </div>
                <div id="img_div_3" style="margin-right: 4px;">
                    <canvas id="img_canvas_3"></canvas>
                </div>
            </div>
        </div>-->
    <div class="right">
      <canvas class='canvas' id='canvas' width='512' height='512'>
        Canvas is not supported. You'll need to try a newer browser version or another browser.
      </canvas>
    </div>
    <p class="text-lg-start">
      <text id="model-progress">Downloading model</text><br />
    <div id="statusWrapper">
      <pre id="status"></pre>
    </div>
    </p>
  </div>
</body>


</html>